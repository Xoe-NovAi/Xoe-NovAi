# ============================================================================
# Xoe-NovAi Phase 1 v0.1.2 - CrawlModule Service Dockerfile
# ============================================================================
# Purpose: Library curation service for 4 external sources
# Last Updated: 2025-10-18
# CRITICAL: Lines 102-105 FIXED - USER command separated from RUN
# ============================================================================

FROM python:3.12-slim AS builder

LABEL maintainer="Xoe-NovAi Team"
LABEL version="0.1.2"

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    git \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

WORKDIR /build

COPY requirements-crawl.txt .

RUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements-crawl.txt

RUN ls -lh /wheels/ && \
    test -f /wheels/crawl4ai-*.whl || (echo "ERROR: crawl4ai wheel not found" && exit 1) && \
    test -f /wheels/yt_dlp-*.whl || (echo "ERROR: yt-dlp wheel not found" && exit 1)

# ============================================================================
# RUNTIME STAGE
# ============================================================================
FROM python:3.12-slim AS runtime

LABEL maintainer="Xoe-NovAi Team"
LABEL version="0.1.2"

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    CRAWL4AI_NO_TELEMETRY=true \
    PATH="/home/appuser/.local/bin:$PATH" \
    PYTHONPATH="/app:$PYTHONPATH" \
    CRAWL4AI_MAX_DEPTH=2 \
    CRAWL_RATE_LIMIT_PER_MIN=30 \
    CRAWL_SANITIZE_SCRIPTS=true \
    CRAWL_MAX_ITEMS=50 \
    CRAWL_CACHE_DIR=/app/cache \
    CRAWL_CACHE_TTL=86400 \
    CRAWL_USER_AGENT="Xoe-NovAi-CrawlModule/0.1.7"

RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    procps \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

RUN groupadd -g 1001 appuser && \
    useradd -m -u 1001 -g appuser -s /bin/bash appuser && \
    mkdir -p /app/XNAi_rag_app && \
    chown -R appuser:appuser /app

COPY --from=builder /wheels /wheels

USER appuser

RUN pip install --no-cache-dir --user /wheels/*.whl

RUN python3 -c "import crawl4ai; print(f'crawl4ai {crawl4ai.__version__} installed')" && \
    python3 -c "import yt_dlp; print(f'yt-dlp installed')" && \
    python3 -c "import os; assert os.getenv('CRAWL4AI_NO_TELEMETRY') == 'true', 'Telemetry not disabled!'"

USER root

RUN mkdir -p \
    /app/cache \
    /library \
    /knowledge/curator && \
    chown -R appuser:appuser \
    /app \
    /library \
    /knowledge

RUN echo "*.gutenberg.org" > /app/allowlist.txt && \
    echo "*.arxiv.org" >> /app/allowlist.txt && \
    echo "*.nih.gov" >> /app/allowlist.txt && \
    echo "*.youtube.com" >> /app/allowlist.txt && \
    chown appuser:appuser /app/allowlist.txt && \
    chmod 444 /app/allowlist.txt

WORKDIR /app/XNAi_rag_app

COPY --chown=appuser:appuser app/XNAi_rag_app/ /app/XNAi_rag_app/

# LINES 102-105: CRITICAL FIX - Separated RUN and USER
RUN test -f /app/XNAi_rag_app/crawl.py || (echo "ERROR: crawl.py not found" && exit 1) && \
    test -f /app/XNAi_rag_app/config_loader.py || (echo "ERROR: config_loader.py not found" && exit 1)

USER appuser

HEALTHCHECK --interval=30s --timeout=15s --start-period=60s --retries=5 \
    CMD python3 -c "import crawl4ai; print('OK')" || exit 1

CMD ["tail", "-f", "/dev/null"]